{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_dense.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kCoPCcGPOd0b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"711f6a88-777c-4b8a-fb33-7db1effb5b35","executionInfo":{"status":"ok","timestamp":1566040262494,"user_tz":-540,"elapsed":639,"user":{"displayName":"한상준","photoUrl":"","userId":"11527713768863174571"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CgUPZNT5On7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"49d0af65-b09d-4649-b914-f54b7a1479b0","executionInfo":{"status":"ok","timestamp":1566040268966,"user_tz":-540,"elapsed":571,"user":{"displayName":"한상준","photoUrl":"","userId":"11527713768863174571"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/cifar10_project')\n","os.getcwd()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/cifar10_project'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"4QISg9V9On5U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"18ed686d-c791-4213-efd2-59dcae92e07f","executionInfo":{"status":"ok","timestamp":1566040272613,"user_tz":-540,"elapsed":2974,"user":{"displayName":"한상준","photoUrl":"","userId":"11527713768863174571"}}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","\n","mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0817 11:11:10.755305 140325568321408 deprecation.py:323] From <ipython-input-3-46c62fe1e279>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","W0817 11:11:10.757248 140325568321408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","W0817 11:11:10.762649 140325568321408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./mnist/data/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0817 11:11:11.024872 140325568321408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","W0817 11:11:11.030142 140325568321408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","W0817 11:11:11.082495 140325568321408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n","Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n","Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qc6YiJJnOqWL","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","  \n","class GAN_dense():\n","    def __init__(self, input_shape = [784], n_noise=128):\n","    \n","        self.input_shape = input_shape\n","        self.n_noise = n_noise\n","        \n","    def get_noise(self, batch_size):\n","        return np.random.uniform(-1.,1., size = [batch_size, self.n_noise])\n","\n","    def generator(self, noise, labels):\n","        with tf.variable_scope('generator',reuse = tf.AUTO_REUSE):\n","            \n","            inputs = tf.concat([noise,labels], 1)\n","            \n","            x = tf.layers.dense(inputs, 256, activation=tf.nn.relu)\n","            x = tf.layers.dense(x, 784, activation=tf.nn.sigmoid)\n","            x = tf.reshape(x,[-1]+self.input_shape)\n","            \n","            return x\n","        \n","    def discriminator(self, inputs, labels):\n","        with tf.variable_scope('discriminator',reuse = tf.AUTO_REUSE):\n","            \n","            x = tf.layers.flatten(inputs)\n","            x = tf.concat([x, labels], 1)\n","            x = tf.layers.dense(x, 256, activation = tf.nn.relu)\n","            x = tf.layers.dense(x, 1, activation = None)\n","            \n","            return x     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qk2xT0k8XJ7q","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.reset_default_graph()\n","\n","input_shape = [784]\n","n_class = 10\n","n_noise=128\n","\n","model = GAN_dense(input_shape = input_shape, n_noise = n_noise)\n","\n","\n","X = tf.placeholder(tf.float32, [None]+input_shape)\n","Y = tf.placeholder(tf.float32, [None,n_class])\n","Z = tf.placeholder(tf.float32, [None,n_noise])\n","\n","G = model.generator(Z,Y)\n","D_real = model.discriminator(X, Y) \n","D_gene = model.discriminator(G,Y)\n","                \n","loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n","                        logits=D_real, labels=tf.ones_like(D_real)))\n","loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n","                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n","loss_D = loss_D_real + loss_D_gene\n","loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n","                        logits=D_gene, labels = tf.ones_like(D_gene)))\n","        \n","vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n","                                  scope = 'discriminator')\n","vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n","                                  scope = 'generator')\n","train_D = tf.train.AdamOptimizer().minimize(loss_D,\n","                                             var_list = vars_D)\n","train_G = tf.train.AdamOptimizer().minimize(loss_G,\n","                                             var_list = vars_G)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"roMpSxL_OqT7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":914},"outputId":"a8fb1db5-7822-4b79-c58c-ebd6cdf17cc1","executionInfo":{"status":"ok","timestamp":1566042010962,"user_tz":-540,"elapsed":116077,"user":{"displayName":"한상준","photoUrl":"","userId":"11527713768863174571"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","total_epoch = 50\n","batch_size = 100\n","\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","total_batch = int(mnist.train.num_examples/batch_size)\n","loss_val_D, loss_val_G = 0, 0\n","\n","for epoch in range(total_epoch):\n","    for i in range(total_batch):\n","        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","        \n","        noise = model.get_noise(batch_size)\n","\n","        _, cost1 = sess.run([train_D, loss_D],\n","                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n","        _, cost2 = sess.run([train_G, loss_G],\n","                                 feed_dict={Y: batch_ys, Z: noise})\n","        loss_val_D += cost1/total_batch\n","        loss_val_G += cost2/total_batch\n","        \n","    print('Epoch:', '%04d' % epoch,\n","          'D loss: {:.4}'.format(loss_val_D),\n","          'G loss: {:.4}'.format(loss_val_G))\n","\n","    if epoch == 0 or (epoch + 1) % 10 == 0:\n","        sample_size = 10\n","        noise = model.get_noise(sample_size)\n","        samples = sess.run(G,\n","                           feed_dict={Y: mnist.test.labels[:sample_size],\n","                                      Z: noise})\n","\n","        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n","\n","        for i in range(sample_size):\n","            ax[0][i].set_axis_off()\n","            ax[1][i].set_axis_off()\n","\n","            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n","            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n","\n","        plt.savefig('samples/dense_mnist_{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n","        plt.close(fig)\n","\n","print('done')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch: 0000 D loss: 0.05668 G loss: 5.896\n","Epoch: 0001 D loss: 0.06678 G loss: 13.54\n","Epoch: 0002 D loss: 0.08265 G loss: 21.54\n","Epoch: 0003 D loss: 0.0996 G loss: 28.5\n","Epoch: 0004 D loss: 0.1233 G loss: 36.02\n","Epoch: 0005 D loss: 0.1488 G loss: 43.54\n","Epoch: 0006 D loss: 0.1841 G loss: 51.72\n","Epoch: 0007 D loss: 0.2446 G loss: 58.91\n","Epoch: 0008 D loss: 0.3278 G loss: 65.91\n","Epoch: 0009 D loss: 0.4335 G loss: 72.63\n","Epoch: 0010 D loss: 0.5858 G loss: 78.77\n","Epoch: 0011 D loss: 0.8076 G loss: 84.39\n","Epoch: 0012 D loss: 1.083 G loss: 89.51\n","Epoch: 0013 D loss: 1.403 G loss: 94.09\n","Epoch: 0014 D loss: 1.791 G loss: 98.5\n","Epoch: 0015 D loss: 2.206 G loss: 102.8\n","Epoch: 0016 D loss: 2.658 G loss: 106.8\n","Epoch: 0017 D loss: 3.164 G loss: 110.5\n","Epoch: 0018 D loss: 3.706 G loss: 113.9\n","Epoch: 0019 D loss: 4.245 G loss: 117.2\n","Epoch: 0020 D loss: 4.821 G loss: 120.4\n","Epoch: 0021 D loss: 5.42 G loss: 123.7\n","Epoch: 0022 D loss: 6.038 G loss: 126.6\n","Epoch: 0023 D loss: 6.678 G loss: 129.5\n","Epoch: 0024 D loss: 7.34 G loss: 132.3\n","Epoch: 0025 D loss: 8.025 G loss: 135.0\n","Epoch: 0026 D loss: 8.711 G loss: 137.7\n","Epoch: 0027 D loss: 9.391 G loss: 140.3\n","Epoch: 0028 D loss: 10.07 G loss: 142.8\n","Epoch: 0029 D loss: 10.77 G loss: 145.3\n","Epoch: 0030 D loss: 11.47 G loss: 147.7\n","Epoch: 0031 D loss: 12.18 G loss: 150.1\n","Epoch: 0032 D loss: 12.89 G loss: 152.4\n","Epoch: 0033 D loss: 13.61 G loss: 154.8\n","Epoch: 0034 D loss: 14.32 G loss: 157.1\n","Epoch: 0035 D loss: 15.03 G loss: 159.4\n","Epoch: 0036 D loss: 15.75 G loss: 161.7\n","Epoch: 0037 D loss: 16.46 G loss: 164.0\n","Epoch: 0038 D loss: 17.18 G loss: 166.3\n","Epoch: 0039 D loss: 17.89 G loss: 168.5\n","Epoch: 0040 D loss: 18.61 G loss: 170.7\n","Epoch: 0041 D loss: 19.33 G loss: 173.0\n","Epoch: 0042 D loss: 20.04 G loss: 175.1\n","Epoch: 0043 D loss: 20.75 G loss: 177.3\n","Epoch: 0044 D loss: 21.46 G loss: 179.5\n","Epoch: 0045 D loss: 22.18 G loss: 181.8\n","Epoch: 0046 D loss: 22.89 G loss: 184.0\n","Epoch: 0047 D loss: 23.6 G loss: 186.2\n","Epoch: 0048 D loss: 24.32 G loss: 188.4\n","Epoch: 0049 D loss: 25.03 G loss: 190.6\n","done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZSLVERLrRknL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}